# Byte-Level Transliteration of Noisy Banglish to Bengali  
### Using ByT5 with Downstream Sentiment Validation

<p align="center">
  <b>A lightweight, robust NLP pipeline for low-resource Banglish text processing</b>
</p>

---

## ðŸ“Œ Overview

Banglish (Bengali written in the Roman alphabet) is widely used in social media and informal communication in Bangladesh. However, Banglish has no fixed spelling rules, which makes it very difficult for traditional Natural Language Processing (NLP) systems to handle.

This project presents a **byte-level transliteration framework** using the **ByT5 transformer model** to convert noisy Banglish text into standard Bengali. To validate the quality of transliteration, a **cross-lingual sentiment analysis pipeline** is introduced.

The system is designed specifically for **low-resource and noisy text environments**.

---

## âœ¨ Key Features

- âœ… Byte-level transliteration (no vocabulary limitation)
- âœ… Handles highly inconsistent Banglish spellings
- âœ… High transliteration accuracy with low error rate
- âœ… Cross-lingual sentiment validation pipeline
- âœ… Suitable for low-resource languages
- âœ… Works well on real-world noisy text

---

## System Architecture

Banglish Text --> ByT5 Transliteration --> Standard Bengali --> English Translation --> Emotion / Sentiment Classification



---

## Dataset

- **Bengaliâ€“Banglish 80K Dataset**
- Approximately 80,000 sentence pairs
- Cleaned and preprocessed
- Data split:
  - 90% Training
  - 10% Testing

---

## Model Details

### ðŸ”¹ Primary Model: ByT5 (Byte-Level Transformer)

- Operates directly on UTF-8 bytes
- Eliminates the Unknown Token (UNK) problem
- Ideal for noisy and code-mixed Banglish text
- Fine-tuned using:
  - Learning rate: `2e-4`
  - Batch size: `8`
  - Epochs: `4`
  - Mixed precision (FP16)

---

## ðŸ“Š Evaluation Metrics

| Metric | Description |
|------|------------|
| BLEU Score | Measures transliteration fluency |
| CER (Character Error Rate) | Measures spelling accuracy |
| Sentiment Confidence | Validates semantic preservation |

---

## Results

### ðŸ”¹ Transliteration Performance

| Metric | Value |
|------|------|
| BLEU Score | **83.32** |
| Character Error Rate (CER) | **3.5%** |
| Validation Loss | 0.022 |

âœ” High-quality Bengali output  
âœ” Very low spelling error  
âœ” Stable training behavior  

---

### ðŸ”¹ Sentiment Pipeline Validation

| Banglish Input | Final Emotion | Confidence |
|---------------|--------------|------------|
| amar khub kharap lagche | Sadness | 0.92 |
| tumi keno amake voy paccho? | Fear | 0.90 |
| tui eto boka keno? | Anger | 0.82 |

The pipeline produces more stable and confident sentiment predictions compared to direct Banglish sentiment analysis.

---

## Limitations

- Some semantic ambiguity remains for slang or context-dependent words
- Errors may propagate across pipeline stages
- Dataset is limited to supervised sentence pairs

---

## Future Work

- Context-aware semantic disambiguation
- End-to-end multilingual emotion classification
- Expansion using real-world social media data
- Extension to other low-resource code-mixed languages

